import os
import logging
import uuid
import requests
from flask import Flask, request, abort
import telebot
from dotenv import load_dotenv
from threading import Thread
from qdrant_client import QdrantClient
from qdrant_client.models import VectorParams, Distance, PointStruct

# ---------------- –õ–û–ì–ò ----------------
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ---------------- –¢–û–ö–ï–ù–´ ----------------
load_dotenv()
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")
QDRANT_URL = os.getenv("QDRANT_URL")
RENDER_URL = os.getenv("RENDER_URL", "https://example.onrender.com")

if not TELEGRAM_TOKEN:
    raise ValueError("TELEGRAM_TOKEN not set")
if not OPENROUTER_API_KEY:
    raise ValueError("OPENROUTER_API_KEY not set")
if not QDRANT_API_KEY or not QDRANT_URL:
    raise ValueError("QDRANT credentials not set")

# ---------------- –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ----------------
app = Flask(__name__)
bot = telebot.TeleBot(TELEGRAM_TOKEN)

# Qdrant –∫–ª–∏–µ–Ω—Ç
qdrant = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)

# –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ (–æ–¥–∏–Ω —Ä–∞–∑)
try:
    qdrant.recreate_collection(
        collection_name="knowledge_base",
        vectors_config=VectorParams(size=1536, distance=Distance.COSINE)
    )
    logger.info("Qdrant collection recreated")
except Exception:
    logger.info("Collection already exists or ignored")

# ---------------- –§–£–ù–ö–¶–ò–ò ----------------
def embed_text(text: str) -> list:
    """–ë–µ—Ä—ë–º —ç–º–±–µ–¥–¥–∏–Ω–≥ —á–µ—Ä–µ–∑ OpenRouter —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –ø—É—Å—Ç–æ–≥–æ –æ—Ç–≤–µ—Ç–∞"""
    try:
        resp = requests.post(
            "https://openrouter.ai/api/v1/embeddings",
            headers={"Authorization": f"Bearer {OPENROUTER_API_KEY}", "Content-Type": "application/json"},
            json={"model": "openai/text-embedding-3-small", "input": text},
            timeout=15
        )
        resp.raise_for_status()
        data = resp.json()
        return data["data"][0]["embedding"]
    except (requests.RequestException, ValueError) as e:
        logger.error(f"–û—à–∏–±–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e} | Response: {getattr(resp, 'text', '–Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞')}")
        return [0.0] * 1536  # –±–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–≥–ª—É—à–∫–∞

def add_doc(doc: str):
    """–î–æ–±–∞–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –≤ Qdrant"""
    vector = embed_text(doc)
    qdrant.upsert(
        collection_name="knowledge_base",
        points=[PointStruct(id=str(uuid.uuid4()), vector=vector, payload={"text": doc})]
    )

def search_docs(query: str, top_k=3):
    """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    vector = embed_text(query)
    results = qdrant.search(collection_name="knowledge_base", query_vector=vector, limit=top_k)
    return [r.payload["text"] for r in results]

# ---------------- –û–°–ù–û–í–ù–û–ô –•–ï–ù–î–õ–ï–† ----------------
def handle_message(message):
    user_id = message.from_user.id
    chat_id = message.chat.id
    user_text = message.text
    logger.info(f"Message from {user_id}: {user_text}")

    # –ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ
    retrieved = search_docs(user_text)
    context = "\n".join(retrieved) if retrieved else "–ù–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è LLM
    messages = [
        {"role": "system", "content": "–¢—ã Asuna Cat ‚Äî –≤–µ—Å–µ–ª–∞—è –∫–æ—à–∫–∞, –∫–æ—Ç–æ—Ä–∞—è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–µ—Ç –∞–Ω–µ–∫–¥–æ—Ç—ã."},
        {"role": "system", "content": f"–í –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–∞—à–ª–æ—Å—å:\n{context}"},
        {"role": "user", "content": user_text},
    ]

    try:
        # –ó–∞–ø—Ä–æ—Å –≤ OpenRouter Chat
        response = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {OPENROUTER_API_KEY}",
                "HTTP-Referer": RENDER_URL,
                "X-Title": "Asuna TG Bot",
                "Content-Type": "application/json",
            },
            json={
                "model": "openai/gpt-3.5-turbo",  # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
                "messages": messages,
                "max_tokens": 800,
                "temperature": 0.7,
            },
            timeout=20
        )
        response.raise_for_status()
        try:
            ai_response = response.json()["choices"][0]["message"]["content"].strip()
        except ValueError:
            logger.error(f"–û—à–∏–±–∫–∞ JSON –æ—Ç OpenRouter: {response.text}")
            ai_response = "–£–ø—Å, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç üòÖ"

        bot.send_message(chat_id, ai_response, parse_mode="Markdown", disable_web_page_preview=True)

    except requests.RequestException as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ OpenRouter: {e}")
        bot.send_message(chat_id, f"–û—à–∏–±–∫–∞ API: {str(e)} üòÖ")

# ---------------- –ö–û–ú–ê–ù–î–´ TELEGRAM ----------------
@bot.message_handler(commands=["start"])
def start_message(message):
    bot.send_message(message.chat.id, "SKYNET BOT ACTIVATE! üòò")

@bot.message_handler(commands=["help"])
def help_message(message):
    bot.send_message(message.chat.id, "/start ‚Äî –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫.\n/add —Ç–µ–∫—Å—Ç ‚Äî –¥–æ–±–∞–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç\n/search —Ç–µ–∫—Å—Ç ‚Äî –ø–æ–∏—Å–∫ –≤ –±–∞–∑–µ")

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
@bot.message_handler(commands=["add"])
def add_document(message):
    text = message.text.replace("/add", "").strip()
    if text:
        add_doc(text)
        bot.send_message(message.chat.id, "–î–æ–∫—É–º–µ–Ω—Ç –¥–æ–±–∞–≤–ª–µ–Ω –≤ –±–∞–∑—É ‚úÖ")
    else:
        bot.send_message(message.chat.id, "–ù–∞–ø–∏—à–∏ —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ /add")

# –ü–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞
@bot.message_handler(commands=["search"])
def search_document(message):
    query = message.text.replace("/search", "").strip()
    if not query:
        bot.send_message(message.chat.id, "–ù–∞–ø–∏—à–∏ —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ /search")
        return
    retrieved = search_docs(query)
    if retrieved:
        result_text = "\n\n".join(f"{i+1}. {doc}" for i, doc in enumerate(retrieved))
        bot.send_message(message.chat.id, f"–ù–∞–π–¥–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã:\n{result_text}")
    else:
        bot.send_message(message.chat.id, "–ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ üòÖ")

# ---------------- –û–ë–†–ê–ë–û–¢–ö–ê –í–°–ï–• –°–û–û–ë–©–ï–ù–ò–ô ----------------
@bot.message_handler(func=lambda message: True)
def echo_all(message):
    Thread(target=handle_message, args=(message,)).start()

# ---------------- FLASK WEBHOOK ----------------
@app.route(f"/{TELEGRAM_TOKEN}", methods=["POST"])
def webhook():
    if request.headers.get("content-type") == "application/json":
        json_string = request.get_data().decode("utf-8")
        update = telebot.types.Update.de_json(json_string)
        bot.process_new_updates([update])
        return ""
    else:
        abort(403)

# ---------------- MAIN ----------------
if __name__ == "__main__":
    webhook_url = f"{RENDER_URL}/{TELEGRAM_TOKEN}"
    bot.remove_webhook()
    bot.set_webhook(url=webhook_url)
    logger.info(f"Webhook set: {webhook_url}")
    port = int(os.getenv("PORT", 10000))
    app.run(host="0.0.0.0", port=port, debug=False)
