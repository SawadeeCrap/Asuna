import os
import logging
import uuid
from threading import Thread

from flask import Flask, request, abort
import telebot
from dotenv import load_dotenv
from qdrant_client import QdrantClient
from qdrant_client.models import VectorParams, Distance, PointStruct
from openai import OpenAI

# ---------------- –õ–û–ì–ò ----------------
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ---------------- –¢–û–ö–ï–ù–´ ----------------
load_dotenv()
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")
QDRANT_URL = os.getenv("QDRANT_URL")
RENDER_URL = os.getenv("RENDER_URL", "https://example.onrender.com")

if not TELEGRAM_TOKEN or not OPENAI_API_KEY or not QDRANT_API_KEY or not QDRANT_URL:
    raise ValueError("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤—Å–µ —Å–µ–∫—Ä–µ—Ç—ã: TELEGRAM, OPENAI, QDRANT")

# ---------------- –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ----------------
app = Flask(__name__)
bot = telebot.TeleBot(TELEGRAM_TOKEN)

# Qdrant –∫–ª–∏–µ–Ω—Ç
qdrant = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)

# OpenAI –∫–ª–∏–µ–Ω—Ç
openai_client = OpenAI(api_key=OPENAI_API_KEY)

# –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
try:
    qdrant.recreate_collection(
        collection_name="knowledge_base",
        vectors_config=VectorParams(size=1536, distance=Distance.COSINE)
    )
    logger.info("Qdrant collection recreated")
except Exception:
    logger.info("Collection already exists –∏–ª–∏ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫—É")

# ---------------- –§–£–ù–ö–¶–ò–ò ----------------
def embed_text(text: str) -> list:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ —á–µ—Ä–µ–∑ OpenAI 1.0 API"""
    if not text.strip():
        return [0.0]*1536
    try:
        resp = openai_client.embeddings.create(
            model="text-embedding-ada-002",
            input=text
        )
        embedding = resp.data[0].embedding
        logger.info(f"–≠–º–±–µ–¥–¥–∏–Ω–≥ –ø–æ–ª—É—á–µ–Ω, –¥–ª–∏–Ω–∞: {len(embedding)}")
        return embedding
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ OpenAI: {e}")
        return [0.0]*1536

def add_doc(doc: str):
    """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ Qdrant"""
    vector = embed_text(doc)
    qdrant.upsert(
        collection_name="knowledge_base",
        points=[PointStruct(id=str(uuid.uuid4()), vector=vector, payload={"text": doc})]
    )
    logger.info(f"–î–æ–∫—É–º–µ–Ω—Ç –¥–æ–±–∞–≤–ª–µ–Ω –≤ –±–∞–∑—É: {doc}")

def search_docs(query: str, top_k=3):
    """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    vector = embed_text(query)
    results = qdrant.search(collection_name="knowledge_base", query_vector=vector, limit=top_k)
    found = [r.payload["text"] for r in results]
    logger.info(f"–ü–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{query}' –≤–µ—Ä–Ω—É–ª: {found}")
    return found

# ---------------- –û–ë–†–ê–ë–û–¢–ö–ê –°–û–û–ë–©–ï–ù–ò–ô ----------------
def handle_message(message):
    user_id = message.from_user.id
    chat_id = message.chat.id
    user_text = message.text
    logger.info(f"–°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç {user_id}: {user_text}")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –±–∞–∑–µ
    add_doc(user_text)

    # –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    retrieved = search_docs(user_text)
    context = "\n".join(retrieved) if retrieved else "–ù–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."

    # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLM
    messages = [
        {"role": "system", "content": "–¢—ã Asuna Cat ‚Äî –≤–µ—Å–µ–ª–∞—è –∫–æ—à–∫–∞, –∫–æ—Ç–æ—Ä–∞—è –æ—Ç–≤–µ—á–∞–µ—Ç —Å–º–µ—à–Ω–æ –∏ –ø–æ –¥–µ–ª—É."},
        {"role": "system", "content": f"–í –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–∞—à–ª–æ—Å—å:\n{context}"},
        {"role": "user", "content": user_text},
    ]

    try:
        resp = openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            max_tokens=800,
            temperature=0.7,
        )
        ai_response = resp.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ OpenAI Chat: {e}")
        ai_response = "–£–ø—Å, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç üòÖ"

    bot.send_message(chat_id, ai_response, parse_mode="Markdown", disable_web_page_preview=True)

# ---------------- –ö–û–ú–ê–ù–î–´ TELEGRAM ----------------
@bot.message_handler(commands=["start"])
def start_message(message):
    bot.send_message(message.chat.id, "SKYNET BOT ACTIVATE! üòò")

@bot.message_handler(commands=["help"])
def help_message(message):
    bot.send_message(message.chat.id, "/start ‚Äî –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫\n/help ‚Äî —Å–ø—Ä–∞–≤–∫–∞")

# ---------------- –û–ë–†–ê–ë–û–¢–ö–ê –í–°–ï–• –°–û–û–ë–©–ï–ù–ò–ô ----------------
@bot.message_handler(func=lambda m: True)
def all_messages(message):
    Thread(target=handle_message, args=(message,)).start()

# ---------------- FLASK WEBHOOK ----------------
@app.route(f"/{TELEGRAM_TOKEN}", methods=["POST"])
def webhook():
    if request.headers.get("content-type") == "application/json":
        json_string = request.get_data().decode("utf-8")
        update = telebot.types.Update.de_json(json_string)
        bot.process_new_updates([update])
        return ""
    else:
        abort(403)

# ---------------- MAIN ----------------
if __name__ == "__main__":
    webhook_url = f"{RENDER_URL}/{TELEGRAM_TOKEN}"
    bot.remove_webhook()
    bot.set_webhook(url=webhook_url)
    logger.info(f"Webhook set: {webhook_url}")
    port = int(os.getenv("PORT", 10000))
    app.run(host="0.0.0.0", port=port, debug=False)
